# Configuration Ansible pour Kubernetes

Ce dossier contient tous les fichiers Ansible nÃ©cessaires pour dÃ©ployer automatiquement un cluster Kubernetes sur l'infrastructure AWS crÃ©Ã©e par Terraform.

## ğŸ“ Structure

```
ansible/
â”œâ”€â”€ playbooks/
â”‚   â”œâ”€â”€ site.yml              # Playbook principal de dÃ©ploiement
â”‚   â”œâ”€â”€ ping.yml              # Test de connectivitÃ©
â”‚   â””â”€â”€ reset.yml             # RÃ©initialisation du cluster
â”œâ”€â”€ roles/
â”‚   â”œâ”€â”€ common/               # PrÃ©paration des nÅ“uds (swap, containerd, etc.)
â”‚   â”œâ”€â”€ kubernetes/           # Installation kubeadm, kubelet, kubectl
â”‚   â”œâ”€â”€ master/               # Initialisation du cluster master
â”‚   â”œâ”€â”€ worker/               # Jointure des workers
â”‚   â””â”€â”€ cni/                  # Installation Flannel/Calico
â”œâ”€â”€ group_vars/
â”‚   â”œâ”€â”€ all.yml               # Variables globales
â”‚   â”œâ”€â”€ masters.yml           # Variables spÃ©cifiques aux masters
â”‚   â””â”€â”€ workers.yml           # Variables spÃ©cifiques aux workers
â”œâ”€â”€ inventories/
â”‚   â””â”€â”€ terraform_inventory.yml # GÃ©nÃ©rÃ© automatiquement
â”œâ”€â”€ ansible.cfg               # Configuration Ansible
â”œâ”€â”€ generate_inventory.sh     # Script de gÃ©nÃ©ration d'inventaire
â””â”€â”€ deploy.sh                # Script de dÃ©ploiement complet
```

## ğŸš€ DÃ©ploiement rapide

### 1. PrÃ©requis
```bash
# Ansible installÃ©
sudo apt update && sudo apt install ansible

# Infrastructure Terraform dÃ©ployÃ©e
cd ../terraform && terraform apply
```

### 2. DÃ©ploiement automatique
```bash
# Script tout-en-un
./deploy.sh
```

### 3. DÃ©ploiement manuel (Ã©tape par Ã©tape)
```bash
# GÃ©nÃ©rer l'inventaire depuis Terraform
./generate_inventory.sh

# Tester la connectivitÃ©
ansible-playbook playbooks/ping.yml

# DÃ©ployer le cluster complet
ansible-playbook playbooks/site.yml
```

## ğŸ¯ DÃ©ploiement par Ã©tapes

### Phase 1: PrÃ©paration
```bash
ansible-playbook playbooks/site.yml --tags preparation
```

### Phase 2: Initialisation master
```bash
ansible-playbook playbooks/site.yml --tags master
```

### Phase 3: Jointure workers
```bash
ansible-playbook playbooks/site.yml --tags worker
```

### Phase 4: CNI
```bash
ansible-playbook playbooks/site.yml --tags cni
```

## âš™ï¸ Configuration

### Variables principales (group_vars/all.yml)
```yaml
kubernetes_version: "1.28"        # Version K8s
pod_network_cidr: "10.244.0.0/16" # RÃ©seau pods
cni_provider: "flannel"           # CNI (flannel/calico)
```

### Changer le CNI
Pour utiliser Calico au lieu de Flannel :
```yaml
# Dans group_vars/all.yml
cni_provider: "calico"
```

## ğŸ”§ Commandes utiles

### Test de connectivitÃ©
```bash
ansible all -m ping
```

### VÃ©rification du cluster
```bash
# Se connecter au master
ssh -i ~/.ssh/id_rsa ubuntu@<MASTER_IP>

# VÃ©rifier les nÅ“uds
kubectl get nodes

# VÃ©rifier les pods systÃ¨me
kubectl get pods -n kube-system
```

### RÃ©initialisation complÃ¨te
```bash
ansible-playbook playbooks/reset.yml
```

## ğŸ›ï¸ RÃ´les dÃ©taillÃ©s

### common
- Mise Ã  jour du systÃ¨me
- DÃ©sactivation du swap
- Configuration des modules kernel
- Installation et configuration de containerd
- Configuration rÃ©seau de base

### kubernetes
- Ajout des repositories Kubernetes
- Installation kubeadm, kubelet, kubectl
- Configuration kubelet
- Verrouillage des versions

### master
- Initialisation du cluster avec kubeadm
- Configuration kubectl pour ubuntu et root
- GÃ©nÃ©ration du token de jointure
- VÃ©rification de l'API server

### worker
- RÃ©cupÃ©ration du token de jointure
- Jointure au cluster
- VÃ©rification du statut kubelet

### cni
- Installation Flannel ou Calico
- Configuration rÃ©seau
- VÃ©rification des pods CNI

## ğŸ› DÃ©pannage

### ProblÃ¨mes de connectivitÃ© SSH
```bash
# VÃ©rifier les clÃ©s SSH
ssh -i ~/.ssh/id_rsa ubuntu@<IP> -v

# RÃ©gÃ©nÃ©rer l'inventaire
./generate_inventory.sh
```

### ProblÃ¨mes de dÃ©ploiement
```bash
# Logs dÃ©taillÃ©s
ansible-playbook playbooks/site.yml -vvv

# VÃ©rifier kubelet
ssh -i ~/.ssh/id_rsa ubuntu@<IP>
sudo journalctl -u kubelet -f
```

### Cluster en erreur
```bash
# Reset et redÃ©ploiement
ansible-playbook playbooks/reset.yml
ansible-playbook playbooks/site.yml
```

## ğŸ“Š Monitoring

### VÃ©rification du cluster
```bash
# Depuis le master
kubectl get nodes -o wide
kubectl get pods --all-namespaces
kubectl cluster-info

# Statut dÃ©taillÃ©
kubectl describe nodes
```

### Logs systÃ¨me
```bash
# Kubelet
sudo journalctl -u kubelet

# Containerd
sudo journalctl -u containerd

# Pods systÃ¨me
kubectl logs -n kube-system <pod-name>
```

## ğŸ”’ SÃ©curitÃ©

### AccÃ¨s au cluster
Le fichier de configuration kubectl est disponible dans :
- `/etc/kubernetes/admin.conf` (root)
- `/home/ubuntu/.kube/config` (ubuntu)

### Copie locale de la configuration
```bash
# Depuis le master
scp -i ~/.ssh/id_rsa ubuntu@<MASTER_IP>:/home/ubuntu/.kube/config ~/.kube/config

# Modifier l'IP du serveur
kubectl config set-cluster kubernetes --server=https://<MASTER_PUBLIC_IP>:6443
```

## ğŸ“ˆ Prochaines Ã©tapes

1. **Ingress Controller** : NGINX, Traefik
2. **Storage** : EBS CSI Driver
3. **Monitoring** : Prometheus, Grafana
4. **Logging** : ELK Stack
5. **CI/CD** : GitLab, Jenkins

## ğŸ¤ Personnalisation

### Ajouter des nÅ“uds
1. Modifier `worker_count` dans Terraform
2. Appliquer : `terraform apply`
3. RÃ©gÃ©nÃ©rer l'inventaire : `./generate_inventory.sh`
4. DÃ©ployer les nouveaux nÅ“uds : `ansible-playbook playbooks/site.yml --limit workers`

### Modifier la configuration
1. Ã‰diter les variables dans `group_vars/`
2. RedÃ©ployer : `ansible-playbook playbooks/site.yml`

## ğŸ“„ Support

- Logs Ansible : Sortie dÃ©taillÃ©e des playbooks
- Documentation Kubernetes : https://kubernetes.io/docs/
- Issues GitHub : Signaler les problÃ¨mes